+++
title = "Spring Semester Update"
date = "2011-03-12"
tags = ["algorithms", "CLRS", "donald knuth", "princeton", "programming",
"theory"]
+++

Today marks the beginning of Spring Break for us and the midway point of the
semester as well. This is most definitely the hardest semester I've ever
had so far and although it's very stressful at times, I'm really
enjoying it a lot. I guess in some ways this semester was a way for me to
determine how much I actually loved computer science at the its core - to
see how much I enjoyed it if I fully immersed myself in it. The results so far
are better than what I had expected: Even though the great majority of the my
homework and assignments are about computer science and even though I am
studying or attending class on some CS subject nearly every single day, my
interest in it has only increased. I feel very at home when learning about the
theoretical aspects of computation and complexity, or knee-deep in the analysis
of some algorithm. Even though the workload is just so very barely manageable,
I'm glad I am taking what I decided to take and I'd like, to the
extent possible, to complete all six courses I am enrolled in this semester. Six
courses is a bit on the high side for an engineer here, but I guess it's
more about how interesting you find them. As I've said before, it only
feels like work if you can actually distinguish it from play. In any case, most
of the work that I have fits comfortably in the category of play, so it's
basically an excuse to do something I'd probably be doing - or
wishing I could be doing - during that time anyway.

I had a few goals for the year. One to take at least one graduate class before
the end of the year; to study lesser known data structures and algorithms; to
learn at least one more popular language and one more obscure language; and to
get an introduction on quantum computation. Of those, I am in the process of
accomplishing the first few of them. Thanks to my class on approximation
algorithms, which is both tough and very enjoyable, I am satisfying the first
one. In my Theory of Algorithms course, we are covering quite a few different
interesting data structures as well as algorithms. Although these are not
exactly "lesser known" in the greater sense of computer science,
they're also not the ones you usually learn in an introductory course.
Specifically, I was very happy to see that we covered Fibonacci heaps,
rank-pairing heaps, AVL trees, and RAVL trees. These, especially the first, are
among the more advanced data structures used for very large data sets in
industry. If I recall correctly, I believe Google Maps uses some implementation
of F-heaps in storing data. In general, self-adjusting data structures are
extremely interesting and it's so neat to get a pretty bound on their
performance regardless of how convoluted the implementation and procedures may
be. As far as the other goals, I'm making (slow) progress on picking up
Python and we're using C++ for our computer graphics course. And as far as
lesser known languages, our compilers course is taught strictly in ML - a
functional language. I am yet to fully wrap my head around those exotic things.
More thought is necessary on that front.

Although I'm satisfied with the coverage of algorithms for trees and
graphs so far, I'm now also interested in learning about probabilistic
algorithms. I was turned in this direction after seeing the power of
probabilistic rounding techniques in solving LP-relaxation problems for
approximation algorithms for very common problems such as vertex cover. Although
they may not always provide an optimal bound, they do sometimes make the code
and analysis much simpler and offer better worst-case performance. And they are
everywhere too. From the example I just mentioned to an implementation of MST in
linear time (!) in the number of edges, randomized and probabilistic algorithms
play a huge role. And looking at it from a more pure sense, it's also
particularly interesting to see how the nature of random numbers can reveal
insight on the structure of computation. I'm starting to develop some
ideas of my own; perhaps the better word for them would be
"questions" or maybe just situations and combinations of known
elements in a way I haven't seen anywhere. Hopefully I will soon be able
to gain the mathematical and analytical machinery to actually see if these ideas
make any sense at all.

In other news, my copy of Knuth's classic Art of Computer Programming Vol.
1-4A finally arrived this week! As you may know, the fourth volume was just
released after something like 38 years. I'm very excited to check it out.
It's currently sitting, still shrink-wrapped, on the table beside me.
During the next week I'll see if I can make sense of it. On another note,
I am very pleasantly surprised by the quality of CLRS, another very excellent
algorithms book. The analysis is surprisingly clean and the writing is precise,
which makes it a pleasure to read. And they tackle complicated concepts with
ease, making it look like it takes hardly any effort, which is impressive. Over
winter break, I had started on Michael Sipser's Introduction to the Theory
of Computation, another classic text. It turns out this gave me a very nice edge
when we were covering DFA/NFAs, regular expressions, and context-free grammars
in compilers. Although I had had an introduction to these concepts in a previous
course, I accredit Sipser's book for teaching them to me in a rigorous
sense. Once again, I see the same ease with with Sipser explains these concepts
and proofs and it's quite impressive. It makes it as painless as possible
to cover these proofs with sufficient depth. So I will have to continue on with
that text, seeing as it coincides very closely with what I am interested in. And
as for the last goal, it is yet unfulfilled. I need a whole lot more knowledge
before I go near that subject. Perhaps next semester or next spring.
There's just so much learn.
